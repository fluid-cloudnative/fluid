/*
Copyright 2023 The Fluid Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package alluxio

import (
	"context"
	"testing"

	datav1alpha1 "github.com/fluid-cloudnative/fluid/api/v1alpha1"
	"github.com/fluid-cloudnative/fluid/pkg/common"
	ctrlhelper "github.com/fluid-cloudnative/fluid/pkg/ctrl"
	"github.com/fluid-cloudnative/fluid/pkg/ddc/base"
	"github.com/fluid-cloudnative/fluid/pkg/utils/fake"
	appsv1 "k8s.io/api/apps/v1"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/utils/ptr"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
)

var _ = Describe("AlluxioEngine Worker Component Tests", Label("pkg.ddc.alluxio.worker_test.go"), func() {
	var (
		dataset        *datav1alpha1.Dataset
		alluxioruntime *datav1alpha1.AlluxioRuntime
		engine         *AlluxioEngine
		mockedObjects  mockedObjects
		client         client.Client
		resources      []runtime.Object
	)
	BeforeEach(func() {
		dataset, alluxioruntime = mockFluidObjectsForTests(types.NamespacedName{Namespace: "fluid", Name: "hbase"})
		engine = mockAlluxioEngineForTests(dataset, alluxioruntime)
		mockedObjects = mockAlluxioObjectsForTests(dataset, alluxioruntime, engine)
		resources = []runtime.Object{
			dataset,
			alluxioruntime,
			mockedObjects.MasterSts,
			mockedObjects.WorkerSts,
			mockedObjects.FuseDs,
		}
	})

	// JustBeforeEach is guaranteed to run after every BeforeEach()
	// So it's easy to modify resources' specs with an extra BeforeEach()
	JustBeforeEach(func() {
		client = fake.NewFakeClientWithScheme(datav1alpha1.UnitTestScheme, resources...)
		engine.Client = client
	})

	Describe("Test AlluxioEngine.CheckWorkersReady()", func() {
		JustBeforeEach(func() {
			engine.Helper = ctrlhelper.BuildHelper(engine.runtimeInfo, engine.Client, engine.Log)
		})
		When("worker is not ready", func() {
			BeforeEach(func() {
				mockedObjects.WorkerSts.Spec.Replicas = ptr.To[int32](1)
				mockedObjects.WorkerSts.Status.Replicas = 1
				mockedObjects.WorkerSts.Status.ReadyReplicas = 0
			})

			It("should return false when worker is not ready", func() {
				ready, err := engine.CheckWorkersReady()
				Expect(err).To(BeNil())
				Expect(ready).To(BeFalse())

				// Check if the runtime status is updated correctly
				updatedRuntime := &datav1alpha1.AlluxioRuntime{}
				err = client.Get(context.TODO(), types.NamespacedName{Name: alluxioruntime.Name, Namespace: alluxioruntime.Namespace}, updatedRuntime)
				Expect(err).To(BeNil())
				Expect(updatedRuntime.Status.WorkerPhase).To(Equal(datav1alpha1.RuntimePhaseNotReady))
				Expect(updatedRuntime.Status.DesiredWorkerNumberScheduled).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.CurrentWorkerNumberScheduled).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.WorkerNumberReady).To(Equal(int32(0)))
			})
		})

		When("worker is fully ready", func() {
			BeforeEach(func() {
				mockedObjects.WorkerSts.Spec.Replicas = ptr.To[int32](1)
				mockedObjects.WorkerSts.Status.ReadyReplicas = 1
				mockedObjects.WorkerSts.Status.Replicas = 1
			})

			It("should return true when worker is ready", func() {
				ready, err := engine.CheckWorkersReady()
				Expect(err).To(BeNil())
				Expect(ready).To(BeTrue())

				// Check if the runtime status is updated correctly
				updatedRuntime := &datav1alpha1.AlluxioRuntime{}
				err = client.Get(context.TODO(), types.NamespacedName{Name: alluxioruntime.Name, Namespace: alluxioruntime.Namespace}, updatedRuntime)
				Expect(err).To(BeNil())
				Expect(updatedRuntime.Status.WorkerPhase).To(Equal(datav1alpha1.RuntimePhaseReady))
				Expect(updatedRuntime.Status.DesiredWorkerNumberScheduled).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.CurrentWorkerNumberScheduled).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.WorkerNumberReady).To(Equal(int32(1)))
			})
		})

		When("worker is partially ready", func() {
			BeforeEach(func() {
				mockedObjects.WorkerSts.Status.Replicas = 3
				mockedObjects.WorkerSts.Spec.Replicas = ptr.To[int32](3)
				mockedObjects.WorkerSts.Status.ReadyReplicas = 1
				mockedObjects.WorkerSts.Status.AvailableReplicas = 1
			})

			It("should return true when worker is partially ready", func() {
				ready, err := engine.CheckWorkersReady()
				Expect(err).To(BeNil())
				Expect(ready).To(BeTrue())

				// Check if the runtime status is updated correctly
				updatedRuntime := &datav1alpha1.AlluxioRuntime{}
				err = client.Get(context.TODO(), types.NamespacedName{Name: alluxioruntime.Name, Namespace: alluxioruntime.Namespace}, updatedRuntime)
				Expect(err).To(BeNil())
				Expect(updatedRuntime.Status.WorkerPhase).To(Equal(datav1alpha1.RuntimePhasePartialReady))
				Expect(updatedRuntime.Status.DesiredWorkerNumberScheduled).To(Equal(int32(3)))
				Expect(updatedRuntime.Status.CurrentWorkerNumberScheduled).To(Equal(int32(3)))
				Expect(updatedRuntime.Status.WorkerNumberReady).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.WorkerNumberAvailable).To(Equal(int32(1)))
				Expect(updatedRuntime.Status.WorkerNumberUnavailable).To(Equal(int32(2)))
			})
		})

		When("worker is in deprecated daemonset mode", func() {
			BeforeEach(func() {
				deprecatedWorkerDaemonSet := &appsv1.DaemonSet{
					ObjectMeta: metav1.ObjectMeta{
						Name:      engine.getWorkerName(),
						Namespace: engine.namespace,
					},
					Spec: appsv1.DaemonSetSpec{},
				}
				resources = []runtime.Object{
					dataset,
					alluxioruntime,
					mockedObjects.MasterSts,
					deprecatedWorkerDaemonSet,
					mockedObjects.FuseDs,
				}
			})

			It("should return true and skip handling for deprecated daemonset", func() {
				ready, err := engine.CheckWorkersReady()
				Expect(err).To(BeNil())
				Expect(ready).To(BeTrue())
			})
		})
	})
})

func TestSetupWorkers(t *testing.T) {

	// runtimeInfoSpark tests create worker in exclusive mode.

	runtimeInfoSpark, err := base.BuildRuntimeInfo("spark", "big-data", common.AlluxioRuntime)

	if err != nil {
		t.Errorf("fail to create the runtimeInfo with error %v", err)
	}
	runtimeInfoSpark.SetupWithDataset(&datav1alpha1.Dataset{
		Spec: datav1alpha1.DatasetSpec{PlacementMode: datav1alpha1.ExclusiveMode},
	})

	// runtimeInfoSpark tests create worker in shareMode mode.
	runtimeInfoHadoop, err := base.BuildRuntimeInfo("hadoop", "big-data", common.AlluxioRuntime)
	if err != nil {
		t.Errorf("fail to create the runtimeInfo with error %v", err)
	}
	runtimeInfoHadoop.SetupWithDataset(&datav1alpha1.Dataset{
		Spec: datav1alpha1.DatasetSpec{PlacementMode: datav1alpha1.ShareMode},
	})
	nodeSelector := map[string]string{
		"node-select": "true",
	}
	runtimeInfoHadoop.SetFuseNodeSelector(nodeSelector)

	type fields struct {
		replicas         int32
		nodeInputs       []*corev1.Node
		worker           *appsv1.StatefulSet
		deprecatedWorker *appsv1.DaemonSet
		runtime          *datav1alpha1.AlluxioRuntime
		runtimeInfo      base.RuntimeInfoInterface
		name             string
		namespace        string
		deprecated       bool
	}
	tests := []struct {
		name             string
		fields           fields
		wantedNodeLabels map[string]map[string]string
	}{
		{
			name: "test0",
			fields: fields{
				replicas: 1,
				nodeInputs: []*corev1.Node{
					{
						ObjectMeta: metav1.ObjectMeta{
							Name: "test-node-spark",
						},
					},
				},
				worker: &appsv1.StatefulSet{

					ObjectMeta: metav1.ObjectMeta{
						Name:      "spark-worker",
						Namespace: "big-data",
					},
					Spec: appsv1.StatefulSetSpec{
						Replicas: ptr.To[int32](1),
					},
				},
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "spark",
						Namespace: "big-data",
					},
					Spec: datav1alpha1.AlluxioRuntimeSpec{
						Replicas: 1,
					},
				},
				runtimeInfo: runtimeInfoSpark,
				name:        "spark",
				namespace:   "big-data",
			},
			wantedNodeLabels: map[string]map[string]string{
				"test-node-spark": {
					"fluid.io/dataset-num":                  "1",
					"fluid.io/s-alluxio-big-data-spark":     "true",
					"fluid.io/s-big-data-spark":             "true",
					"fluid.io/s-h-alluxio-t-big-data-spark": "0B",
					"fluid_exclusive":                       "big-data_spark",
				},
			},
		},
		{
			name: "test1",
			fields: fields{
				replicas: 1,
				worker: &appsv1.StatefulSet{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "hadoop-worker",
						Namespace: "big-data",
					},
					Spec: appsv1.StatefulSetSpec{
						Replicas: ptr.To[int32](1),
					},
				},
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "hadoop",
						Namespace: "big-data",
					},
					Spec: datav1alpha1.AlluxioRuntimeSpec{
						Replicas: 1,
					},
				},
				runtimeInfo: runtimeInfoHadoop,
				name:        "hadoop",
				namespace:   "big-data",
			},
			wantedNodeLabels: map[string]map[string]string{
				"test-node-hadoop": {
					"fluid.io/dataset-num":                   "1",
					"fluid.io/s-alluxio-big-data-hadoop":     "true",
					"fluid.io/s-big-data-hadoop":             "true",
					"fluid.io/s-h-alluxio-t-big-data-hadoop": "0B",
				},
			},
		}, {
			name: "deprecated",
			fields: fields{
				replicas: 0,
				worker:   &appsv1.StatefulSet{},
				deprecatedWorker: &appsv1.DaemonSet{ObjectMeta: metav1.ObjectMeta{
					Name:      "deprecated-worker",
					Namespace: "big-data",
				}},
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "deprecated",
						Namespace: "big-data",
					},
					Spec: datav1alpha1.AlluxioRuntimeSpec{
						Replicas: 1,
					},
				},
				runtimeInfo: runtimeInfoHadoop,
				name:        "deprecated",
				namespace:   "big-data",
				deprecated:  true,
			},
			wantedNodeLabels: map[string]map[string]string{
				"test-node-hadoop": {
					"fluid.io/dataset-num":                   "1",
					"fluid.io/s-alluxio-big-data-hadoop":     "true",
					"fluid.io/s-big-data-hadoop":             "true",
					"fluid.io/s-h-alluxio-t-big-data-hadoop": "0B",
				},
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			runtimeObjs := []runtime.Object{}
			for _, nodeInput := range tt.fields.nodeInputs {
				runtimeObjs = append(runtimeObjs, nodeInput.DeepCopy())
			}

			runtimeObjs = append(runtimeObjs, tt.fields.worker.DeepCopy())

			s := runtime.NewScheme()
			data := &datav1alpha1.Dataset{
				ObjectMeta: metav1.ObjectMeta{
					Name:      tt.fields.name,
					Namespace: tt.fields.namespace,
				},
			}
			s.AddKnownTypes(datav1alpha1.GroupVersion, tt.fields.runtime)
			s.AddKnownTypes(datav1alpha1.GroupVersion, data)
			s.AddKnownTypes(appsv1.SchemeGroupVersion, tt.fields.worker)
			if tt.fields.deprecatedWorker != nil {
				s.AddKnownTypes(appsv1.SchemeGroupVersion, tt.fields.deprecatedWorker)
			}
			_ = corev1.AddToScheme(s)
			runtimeObjs = append(runtimeObjs, tt.fields.runtime)
			if tt.fields.deprecatedWorker != nil {
				runtimeObjs = append(runtimeObjs, tt.fields.deprecatedWorker)
			}
			runtimeObjs = append(runtimeObjs, data)
			mockClient := fake.NewFakeClientWithScheme(s, runtimeObjs...)

			e := &AlluxioEngine{
				runtime:     tt.fields.runtime,
				runtimeInfo: tt.fields.runtimeInfo,
				Client:      mockClient,
				name:        tt.fields.name,
				namespace:   tt.fields.namespace,
				Log:         ctrl.Log.WithName(tt.fields.name),
			}

			e.Helper = ctrlhelper.BuildHelper(tt.fields.runtimeInfo, mockClient, e.Log)
			err := e.SetupWorkers()
			if err != nil {
				t.Errorf("testCase %s AlluxioEngine.SetupWorkers() error = %v", tt.name, err)
			}

			if !tt.fields.deprecated {
				if tt.fields.replicas != *tt.fields.worker.Spec.Replicas {
					t.Errorf("Failed to scale %v for %v", tt.name, tt.fields)
				}
			}
		})
	}
}

func TestShouldSetupWorkers(t *testing.T) {
	type fields struct {
		name      string
		namespace string
		runtime   *datav1alpha1.AlluxioRuntime
	}
	tests := []struct {
		name       string
		fields     fields
		wantShould bool
		wantErr    bool
	}{
		{
			name: "test0",
			fields: fields{
				name:      "spark",
				namespace: "big-data",
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "spark",
						Namespace: "big-data",
					},
					Status: datav1alpha1.RuntimeStatus{
						WorkerPhase: datav1alpha1.RuntimePhaseNone,
					},
				},
			},
			wantShould: true,
			wantErr:    false,
		},
		{
			name: "test1",
			fields: fields{
				name:      "hadoop",
				namespace: "big-data",
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "hadoop",
						Namespace: "big-data",
					},
					Status: datav1alpha1.RuntimeStatus{
						WorkerPhase: datav1alpha1.RuntimePhaseNotReady,
					},
				},
			},
			wantShould: false,
			wantErr:    false,
		},
		{
			name: "test2",
			fields: fields{
				name:      "hbase",
				namespace: "big-data",
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "hbase",
						Namespace: "big-data",
					},
					Status: datav1alpha1.RuntimeStatus{
						WorkerPhase: datav1alpha1.RuntimePhasePartialReady,
					},
				},
			},
			wantShould: false,
			wantErr:    false,
		},
		{
			name: "test3",
			fields: fields{
				name:      "tensorflow",
				namespace: "ml",
				runtime: &datav1alpha1.AlluxioRuntime{
					ObjectMeta: metav1.ObjectMeta{
						Name:      "tensorflow",
						Namespace: "ml",
					},
					Status: datav1alpha1.RuntimeStatus{
						WorkerPhase: datav1alpha1.RuntimePhaseReady,
					},
				},
			},
			wantShould: false,
			wantErr:    false,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			runtimeObjs := []runtime.Object{}
			data := &datav1alpha1.Dataset{
				ObjectMeta: metav1.ObjectMeta{
					Name:      tt.fields.name,
					Namespace: tt.fields.namespace,
				},
			}

			s := runtime.NewScheme()
			s.AddKnownTypes(datav1alpha1.GroupVersion, tt.fields.runtime)
			s.AddKnownTypes(datav1alpha1.GroupVersion, data)
			_ = corev1.AddToScheme(s)
			runtimeObjs = append(runtimeObjs, tt.fields.runtime, data)
			mockClient := fake.NewFakeClientWithScheme(s, runtimeObjs...)
			e := &AlluxioEngine{
				name:      tt.fields.name,
				namespace: tt.fields.namespace,
				runtime:   tt.fields.runtime,
				Client:    mockClient,
			}

			gotShould, err := e.ShouldSetupWorkers()
			if (err != nil) != tt.wantErr {
				t.Errorf("AlluxioEngine.ShouldSetupWorkers() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if gotShould != tt.wantShould {
				t.Errorf("AlluxioEngine.ShouldSetupWorkers() = %v, want %v", gotShould, tt.wantShould)
			}
		})
	}
}

func TestGetWorkerSelectors(t *testing.T) {
	type fields struct {
		name string
	}
	tests := []struct {
		name   string
		fields fields
		want   string
	}{
		{
			name: "test0",
			fields: fields{
				name: "spark",
			},
			want: "app=alluxio,release=spark,role=alluxio-worker",
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			e := &AlluxioEngine{
				name: tt.fields.name,
			}
			if got := e.getWorkerSelectors(); got != tt.want {
				t.Errorf("AlluxioEngine.getWorkerSelectors() = %v, want %v", got, tt.want)
			}
		})
	}
}
